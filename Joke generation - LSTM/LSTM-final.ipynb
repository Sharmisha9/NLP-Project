{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 03:14:50.758905: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-14 03:14:50.763746: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-14 03:14:50.828517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import required libraries\n",
    "!pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[me narrating a documentary about narrators] \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Telling my daughter garlic is good for you. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I've been going through a really rough period ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If I could have dinner with anyone, dead or al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Two guys walk into a bar. The third guy ducks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Joke\n",
       "0   1  [me narrating a documentary about narrators] \"...\n",
       "1   2  Telling my daughter garlic is good for you. Go...\n",
       "2   3  I've been going through a really rough period ...\n",
       "3   4  If I could have dinner with anyone, dead or al...\n",
       "4   5     Two guys walk into a bar. The third guy ducks."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes_df = pd.read_csv('shortjokes.csv')\n",
    "jokes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  100000\n",
      "Number of fields:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records: \", jokes_df.shape[0])\n",
    "print(\"Number of fields: \", jokes_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [me narrating a documentary about narrators] \"...\n",
       "1        Telling my daughter garlic is good for you. Go...\n",
       "2        I've been going through a really rough period ...\n",
       "3        If I could have dinner with anyone, dead or al...\n",
       "4           Two guys walk into a bar. The third guy ducks.\n",
       "                               ...                        \n",
       "99995    Every time I walk into a singles bar I can hea...\n",
       "99996    how wide is the universe? how long is a piece ...\n",
       "99997    A man goes to a halloween party wearing nothin...\n",
       "99998                           I don't Bolivia Peru-v it.\n",
       "99999    What's the world's longest Ted Talk? How I Met...\n",
       "Name: Joke, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes_df['Joke']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke</th>\n",
       "      <th>Cleaned_Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[me narrating a documentary about narrators] \"...</td>\n",
       "      <td>me narrating documentary about narrators can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telling my daughter garlic is good for you. Go...</td>\n",
       "      <td>telling my daughter garlic is good for you goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've been going through a really rough period ...</td>\n",
       "      <td>i ve been going through really rough period at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I could have dinner with anyone, dead or al...</td>\n",
       "      <td>if could have dinner with anyone dead or alive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two guys walk into a bar. The third guy ducks.</td>\n",
       "      <td>two guys walk into bar the third guy ducks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Every time I walk into a singles bar I can hea...</td>\n",
       "      <td>every time walk into singles bar can hear mom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>how wide is the universe? how long is a piece ...</td>\n",
       "      <td>how wide is the universe how long is piece of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>A man goes to a halloween party wearing nothin...</td>\n",
       "      <td>a man goes to halloween party wearing nothing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>I don't Bolivia Peru-v it.</td>\n",
       "      <td>i don bolivia peru it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>What's the world's longest Ted Talk? How I Met...</td>\n",
       "      <td>what the world longest ted talk how met your m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Joke  \\\n",
       "0      [me narrating a documentary about narrators] \"...   \n",
       "1      Telling my daughter garlic is good for you. Go...   \n",
       "2      I've been going through a really rough period ...   \n",
       "3      If I could have dinner with anyone, dead or al...   \n",
       "4         Two guys walk into a bar. The third guy ducks.   \n",
       "...                                                  ...   \n",
       "99995  Every time I walk into a singles bar I can hea...   \n",
       "99996  how wide is the universe? how long is a piece ...   \n",
       "99997  A man goes to a halloween party wearing nothin...   \n",
       "99998                         I don't Bolivia Peru-v it.   \n",
       "99999  What's the world's longest Ted Talk? How I Met...   \n",
       "\n",
       "                                            Cleaned_Joke  \n",
       "0       me narrating documentary about narrators can ...  \n",
       "1      telling my daughter garlic is good for you goo...  \n",
       "2      i ve been going through really rough period at...  \n",
       "3      if could have dinner with anyone dead or alive...  \n",
       "4            two guys walk into bar the third guy ducks   \n",
       "...                                                  ...  \n",
       "99995  every time walk into singles bar can hear mom ...  \n",
       "99996  how wide is the universe how long is piece of ...  \n",
       "99997  a man goes to halloween party wearing nothing ...  \n",
       "99998                             i don bolivia peru it   \n",
       "99999  what the world longest ted talk how met your m...  \n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the Joke column\n",
    "jokes_df['Cleaned_Joke'] = jokes_df['Joke'].apply(clean_text)\n",
    "\n",
    "jokes_df[['Joke', 'Cleaned_Joke']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46923"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizer process\n",
    "tokenizer = Tokenizer()\n",
    "#fit\n",
    "tokenizer.fit_on_texts(jokes_df['Joke'])\n",
    "#assign length of word index\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#declaring ngrams\n",
    "input_sequences = []\n",
    "#spliting the sentence\n",
    "for line in jokes_df['Joke']:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 8701],\n",
       " [14, 8701, 1],\n",
       " [14, 8701, 1, 3039],\n",
       " [14, 8701, 1, 3039, 43],\n",
       " [14, 8701, 1, 3039, 43, 25110]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   14, 8701],\n",
       "       [   0,    0,    0, ...,   14, 8701,    1],\n",
       "       [   0,    0,    0, ..., 8701,    1, 3039],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   27,    3,  620],\n",
       "       [   0,    0,    0, ...,    3,  620,   23],\n",
       "       [   0,    0,    0, ...,  620,   23,  379]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_rows = 100000\n",
    "total_words = 46923\n",
    "batch_size = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_generator(y, batch_size, total_words):\n",
    "    num_batches = int(np.ceil(len(y) / batch_size))\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = min(start + batch_size, len(y))  \n",
    "        y_batch = y[start:end]\n",
    "        y_batch_encoded = tf.keras.utils.to_categorical(y_batch, num_classes=total_words)\n",
    "        yield y_batch_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = padded_input_sequences[:,-1]\n",
    "# Using the generator to process data\n",
    "for encoded_batch in batch_generator(y, batch_size, total_words):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,692,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46923</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,085,373</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │     \u001b[38;5;34m4,692,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46923\u001b[0m)          │     \u001b[38;5;34m7,085,373\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,928,273</span> (45.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,928,273\u001b[0m (45.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,928,273</span> (45.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,928,273\u001b[0m (45.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "total_words = 46923\n",
    "  \n",
    "max_sequence_len = 10  \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, max_sequence_len-1))\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1411s\u001b[0m 435ms/step - accuracy: 0.0721 - loss: 6.9527\n",
      "Epoch 2/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1478s\u001b[0m 440ms/step - accuracy: 0.1607 - loss: 5.7324\n",
      "Epoch 3/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1387s\u001b[0m 428ms/step - accuracy: 0.2303 - loss: 4.6811\n",
      "Epoch 7/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1392s\u001b[0m 425ms/step - accuracy: 0.2417 - loss: 4.5312\n",
      "Epoch 8/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1395s\u001b[0m 423ms/step - accuracy: 0.2528 - loss: 4.4042\n",
      "Epoch 9/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1410s\u001b[0m 435ms/step - accuracy: 0.2635 - loss: 4.2874\n",
      "Epoch 10/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1438s\u001b[0m 427ms/step - accuracy: 0.2742 - loss: 4.1835\n",
      "Epoch 11/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1380s\u001b[0m 426ms/step - accuracy: 0.2836 - loss: 4.0947\n",
      "Epoch 12/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1371s\u001b[0m 416ms/step - accuracy: 0.2932 - loss: 4.0127\n",
      "Epoch 13/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1401s\u001b[0m 416ms/step - accuracy: 0.3019 - loss: 3.9382\n",
      "Epoch 14/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1318s\u001b[0m 406ms/step - accuracy: 0.3104 - loss: 3.8739\n",
      "Epoch 15/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1351s\u001b[0m 417ms/step - accuracy: 0.3175 - loss: 3.8168\n",
      "Epoch 16/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1475s\u001b[0m 439ms/step - accuracy: 0.3250 - loss: 3.7562\n",
      "Epoch 17/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1315s\u001b[0m 406ms/step - accuracy: 0.3323 - loss: 3.7024\n",
      "Epoch 18/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1299s\u001b[0m 401ms/step - accuracy: 0.3380 - loss: 3.6554\n",
      "Epoch 19/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1323s\u001b[0m 408ms/step - accuracy: 0.3438 - loss: 3.6130\n",
      "Epoch 20/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1307s\u001b[0m 397ms/step - accuracy: 0.3491 - loss: 3.5734\n",
      "Epoch 21/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1378s\u001b[0m 408ms/step - accuracy: 0.3545 - loss: 3.5338\n",
      "Epoch 22/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1322s\u001b[0m 408ms/step - accuracy: 0.3581 - loss: 3.5007\n",
      "Epoch 23/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1313s\u001b[0m 399ms/step - accuracy: 0.3627 - loss: 3.4711\n",
      "Epoch 24/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1367s\u001b[0m 406ms/step - accuracy: 0.3672 - loss: 3.4377\n",
      "Epoch 25/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1321s\u001b[0m 407ms/step - accuracy: 0.3715 - loss: 3.4118\n",
      "Epoch 26/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1327s\u001b[0m 403ms/step - accuracy: 0.3750 - loss: 3.3825\n",
      "Epoch 27/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1307s\u001b[0m 403ms/step - accuracy: 0.3778 - loss: 3.3605\n",
      "Epoch 28/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1348s\u001b[0m 405ms/step - accuracy: 0.3820 - loss: 3.3328\n",
      "Epoch 29/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1346s\u001b[0m 406ms/step - accuracy: 0.3839 - loss: 3.3126\n",
      "Epoch 30/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1334s\u001b[0m 404ms/step - accuracy: 0.3867 - loss: 3.2957\n",
      "Epoch 31/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1312s\u001b[0m 405ms/step - accuracy: 0.3901 - loss: 3.2741\n",
      "Epoch 32/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1337s\u001b[0m 403ms/step - accuracy: 0.3921 - loss: 3.2560\n",
      "Epoch 33/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1396s\u001b[0m 428ms/step - accuracy: 0.3976 - loss: 3.2204\n",
      "Epoch 35/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1403s\u001b[0m 428ms/step - accuracy: 0.3999 - loss: 3.2049\n",
      "Epoch 36/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1252s\u001b[0m 386ms/step - accuracy: 0.4018 - loss: 3.1869\n",
      "Epoch 37/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1336s\u001b[0m 403ms/step - accuracy: 0.4042 - loss: 3.1758\n",
      "Epoch 38/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1287s\u001b[0m 397ms/step - accuracy: 0.4076 - loss: 3.1506\n",
      "Epoch 40/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1310s\u001b[0m 404ms/step - accuracy: 0.4098 - loss: 3.1343\n",
      "Epoch 41/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1351s\u001b[0m 407ms/step - accuracy: 0.4112 - loss: 3.1241\n",
      "Epoch 42/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1352s\u001b[0m 410ms/step - accuracy: 0.4130 - loss: 3.1157\n",
      "Epoch 43/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1329s\u001b[0m 406ms/step - accuracy: 0.4147 - loss: 3.1013\n",
      "Epoch 44/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1300s\u001b[0m 393ms/step - accuracy: 0.4166 - loss: 3.0881\n",
      "Epoch 45/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1304s\u001b[0m 400ms/step - accuracy: 0.4177 - loss: 3.0814\n",
      "Epoch 46/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1366s\u001b[0m 407ms/step - accuracy: 0.4181 - loss: 3.0786\n",
      "Epoch 47/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1336s\u001b[0m 406ms/step - accuracy: 0.4200 - loss: 3.0614\n",
      "Epoch 48/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1344s\u001b[0m 406ms/step - accuracy: 0.4207 - loss: 3.0555\n",
      "Epoch 49/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1317s\u001b[0m 406ms/step - accuracy: 0.4221 - loss: 3.0485\n",
      "Epoch 50/50\n",
      "\u001b[1m3243/3243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1333s\u001b[0m 403ms/step - accuracy: 0.4228 - loss: 3.0415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f24827471c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Convert labels to a sparse matrix format\n",
    "y_sparse = np.array(y, dtype='int32')  # Ensure y is an integer array for sparse representation\n",
    "\n",
    "# sparse categorical crossentropy loss to handle sparse labels\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model with sparse labels\n",
    "model.fit(X, y_sparse, epochs=50,  batch_size= 512)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
